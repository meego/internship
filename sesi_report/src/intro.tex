\chapter{Introduction}
\label{chap:intro}

  Depuis le début des années 2000, une des plus anciennes loi de l'informatique
  commence à montrer ses limites: la loi de Moore. Les constructeurs de matériel
  ont cessé d'augmenter la fréquence des processeurs, pour des raisons
  énergétiques. En effet, cette augmentation va de pair avec celle de la
  consommation électrique, qui devient impossible à assurer. De plus, il devient
  de plus en plus difficile de refroidir les machines sans introduire de
  nouvelles technologies comme le water cooling~\citep{googleXXXXdatacenters},
  qui sont très coûteuses, et aussi très énergivores. Les entreprises font donc
  le choix d'augmenter le nombre de c\oe urs par processeur, ainsi que le nombre
  de processeurs pour faire face à ces difficultés. De nos jours, des
  architectures avec une cinquantaine de c\oe urs sont courantes, et d'autres
  comportant plusieurs centaines voire milliers de c\oe urs sont à
  prévoir. L'augmentation des processeurs sur les puces entraine inévitablement
  une augmentation de la mémoire, et ce pour des raisons évidentes de
  performance. En plus de centaines de c\oe urs, les systèmes doivent maintenant
  faire face à d'énormes quantités de mémoire~\citep{hp2012z820,
    puget2013z9pe}. Il est donc nécessaire de revoir ces systèmes et de les
  adapter pour gérer efficacement ces ressources.\\

  Dans le cadre de ce stage, nous faisons face à plusieurs
  problèmes. L'architecture matérielle considérée est l'architecture
  TSAR~\citep{greiner2009tsar} développée au LIP6. Celle-ci offre notamment 1To
  de mémoire physique. Pour des raisons énergétiques, les processeurs de cette
  architecture sont des processeurs 32 bits, qui sont donc limités à 4Go
  d'espace adressable. Ainsi, le premier problème consiste à gérer, depuis le
  noyau, un espace mémoire supérieur à l'espace mémoire adressable des
  processeurs.

  Deuxièment, cette architecture est une architecture NUMA à mémoire partagée
  cohérente, composée de 1024 coeurs répartis en clusters. Afin de pouvoir gérer
  efficacement le matériel, un système d'exploitation a été spécialement
  développé: ALMOS~\citep{almaless2011almos}. Ce système est basé sur un noyau
  monolithique, tout comme Linux ou *BSD. Son but est de répondre à l'un des
  enjeux des architecture NUMA, à savoir gérer efficacement le placement en
  mémoire des données et le placement des threads accédant à ces données.

  Troisièmement, du fait de l'espace d'adressage de 40 bits, ALMOS est en train
  d'être transformé en multi-noyau. En conséquence de cela, il est nécessaire de
  maintenir certaines informations cohérentes entre tous les noyaux en cours
  d'exécution, et particulièrement les structures noyaux partagées par les
  processus tel que les descripteurs de fichiers ou les zones mémoires. Cette
  cohérence permet entre autre de donner l'illusion à l'utilisateur de n'avoir
  qu'un seul système en cours d'exécution sur la machine; essentiel pour le
  support des applications en mémoire partagées.

  Notre travail consiste principalement à supporter le mécanisme de création
  distante et de migration de threads entre les noyaux, et d'assurer la
  cohérence des structures partagées entre eux.\\

  Ce document est organisé de la manière suivante: dans le
  chapitre~\ref{chap:subject}, nous présenterons le sujet du stage et la
  problématique. Le chapitre~\ref{chap:sol} expliquera la solution envisagée
  pour ce répondre à la problématique. Ensuite, nous donnerons dans le
  chapitre~\ref{chap:tasks} le découpage des tâches identifié. Enfin, nous
  donnerons dans le chapitre~\ref{chap:tests} la procédure de recette qui sera
  utilisée pour valider notre solution, et dans le chapitre~\ref{chap:sched}
  l'échéancier retenu pour ce travail.
